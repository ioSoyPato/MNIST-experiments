{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificación de Dígitos Manuscritos Usando Diferentes Modelos de Machine Learning\n",
    "\n",
    "En esta actividad, utilizaremos el conjunto de datos MNIST, que contiene imágenes de dígitos manuscritos, para entrenar y evaluar diversos modelos de Machine Learning y Deep Learning. Vamos a probar los siguientes modelos:\n",
    "1. **Regresión Logística**\n",
    "2. **K-Nearest Neighbors (KNN)**\n",
    "3. **Support Vector Machines (SVM)**\n",
    "4. **Random Forest**\n",
    "5. **Redes Neuronales (MLP)**\n",
    "6. **Convolutional Neural Networks (CNN)**\n",
    "\n",
    "## Carga de Librerías\n",
    "\n",
    "Primero, cargamos las librerías necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 16:30:35.101213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-23 16:30:35.162552: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-23 16:30:35.181715: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-23 16:30:35.290098: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-23 16:30:36.357005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y Preparación del Conjunto de Datos MNIST\n",
    "\n",
    "El conjunto de datos MNIST se carga desde TensorFlow. Vamos a dividirlo en dos partes: 60,000 imágenes para el conjunto de entrenamiento y 10,000 imágenes para el conjunto de prueba.\n",
    "\n",
    "Para los modelos de **Regresión Logística**, **KNN**, **SVM**, y **Random Forest**, las imágenes se deben aplanar a vectores 1D. Para las redes neuronales (CNN y MLP), las imágenes se normalizan y se estructuran en un formato adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos MNIST\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Aplanar imágenes para modelos clásicos de ML\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1) / 255.0\n",
    "\n",
    "# Normalizar datos para redes neuronales\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1: Regresión Logística\n",
    "\n",
    "Probamos la **Regresión Logística** para clasificar los dígitos manuscritos. Este modelo es simple pero efectivo para problemas lineales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.93      0.90      0.91      1032\n",
      "           3       0.90      0.91      0.91      1010\n",
      "           4       0.94      0.94      0.94       982\n",
      "           5       0.90      0.87      0.89       892\n",
      "           6       0.94      0.95      0.95       958\n",
      "           7       0.93      0.92      0.93      1028\n",
      "           8       0.88      0.88      0.88       974\n",
      "           9       0.91      0.92      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Regresión Logística\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(x_train_flat, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred_log_reg = log_reg.predict(x_test_flat)\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2: K-Nearest Neighbors (KNN)\n",
    "\n",
    "A continuación, utilizamos el algoritmo **KNN** con 3 vecinos. Este modelo clasifica los datos según la proximidad a otros puntos en el espacio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.96      1.00      0.98      1135\n",
      "           2       0.98      0.97      0.97      1032\n",
      "           3       0.96      0.97      0.96      1010\n",
      "           4       0.98      0.97      0.97       982\n",
      "           5       0.97      0.96      0.96       892\n",
      "           6       0.98      0.99      0.98       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.99      0.94      0.96       974\n",
      "           9       0.96      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train_flat, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred_knn = knn.predict(x_test_flat)\n",
    "print(\"K-Nearest Neighbors:\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 3: Support Vector Machine (SVM)\n",
    "\n",
    "El modelo **SVM** con kernel RBF se utiliza para identificar los dígitos. Este modelo es poderoso para problemas de clasificación no lineales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.98      0.99      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.98      0.98      0.98       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm = SVC(kernel='rbf', C=10)\n",
    "svm.fit(x_train_flat, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred_svm = svm.predict(x_test_flat)\n",
    "print(\"SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 4: Random Forest\n",
    "\n",
    "El modelo **Random Forest** es un conjunto de árboles de decisión, útil para problemas de clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.96      0.97      0.97      1032\n",
      "           3       0.96      0.96      0.96      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.97      0.96      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.96      0.97      1028\n",
      "           8       0.96      0.96      0.96       974\n",
      "           9       0.96      0.95      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(x_train_flat, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred_rf = random_forest.predict(x_test_flat)\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 5: Red Neuronal Multicapa (MLP)\n",
    "\n",
    "Usamos una **Red Neuronal Multicapa (MLP)** con dos capas ocultas para clasificar los dígitos. Este modelo es una red neuronal artificial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network (MLP):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.97      0.98      0.98      1010\n",
      "           4       0.97      0.98      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.99      0.98      0.98       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.98      0.97      0.97       974\n",
      "           9       0.98      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Red Neuronal Multicapa (MLP)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=300, solver='adam')\n",
    "mlp.fit(x_train_flat, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred_mlp = mlp.predict(x_test_flat)\n",
    "print(\"Neural Network (MLP):\")\n",
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 6: Convolutional Neural Network (CNN)\n",
    "\n",
    "Finalmente, probamos una **Red Neuronal Convolucional (CNN)**, la cual es particularmente adecuada para la clasificación de imágenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iosoypato/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727130900.411877  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727130900.520961  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727130900.521211  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727130900.522732  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727130900.522939  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727130900.523133  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727130900.580914  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727130900.581206  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727130900.581477  212192 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-23 16:35:00.581671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4284 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 16:35:01.007971: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150528000 exceeds 10% of free system memory.\n",
      "2024-09-23 16:35:01.153529: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150528000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Red Neuronal Convolucional (CNN)\n",
    "cnn_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo CNN\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo CNN\n",
    "cnn_model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
    "\n",
    "# Evaluación\n",
    "cnn_score = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"CNN Test Loss: {cnn_score[0]}, Test Accuracy: {cnn_score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variación de la Red Neuronal (MLP)\n",
    "\n",
    "Aquí probamos una variación de la **Red Neuronal Multicapa (MLP)** con una arquitectura diferente y un optimizador basado en descenso de gradiente estocástico (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variación de MLP\n",
    "mlp_variant = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, solver='sgd', learning_rate_init=0.01)\n",
    "mlp_variant.fit(x_train_flat, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred_mlp_variant = mlp_variant.predict(x_test_flat)\n",
    "print(\"Neural Network (MLP) Variant:\")\n",
    "print(classification_report(y_test, y_pred_mlp_variant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predecir datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En esta actividad, hemos entrenado y evaluado varios modelos de Machine Learning y Deep Learning para la identificación de dígitos manuscritos usando el conjunto de datos MNIST. Cada modelo tiene sus ventajas y desventajas, siendo las redes neuronales convolucionales (CNN) las más adecuadas para la tarea de clasificación de imágenes.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Cargar el dataset MNIST\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocesar los datos\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# Crear el modelo\n",
    "cnn_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "cnn_model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "cnn_model.save(\"mnist_cnn_model.h5\")\n",
    "\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "loaded_model = keras.models.load_model(\"mnist_cnn_model.h5\")\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_acc = loaded_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Función para cargar y preprocesar la imagen\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert('L')  # Convertir a escala de grises\n",
    "    img = img.resize((28, 28))  # Redimensionar a 28x28\n",
    "    img = np.array(img)  # Convertir a un arreglo numpy\n",
    "    img = img / 255.0  # Normalizar\n",
    "    img = img.reshape(1, 28, 28, 1)  # Darle la forma correcta\n",
    "    return img\n",
    "\n",
    "# Cargar y preprocesar una imagen\n",
    "image = load_and_preprocess_image('my_digit.png')\n",
    "\n",
    "# Hacer una predicción\n",
    "prediction = loaded_model.predict(image)\n",
    "predicted_class = np.argmax(prediction)\n",
    "print(f\"El modelo predice que es un {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
